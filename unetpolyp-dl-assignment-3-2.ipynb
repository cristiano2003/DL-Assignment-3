{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6938815,"sourceType":"datasetVersion","datasetId":3984786}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":18530.560339,"end_time":"2023-11-16T07:28:56.181951","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-11-16T02:20:05.621612","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchsummary\n!pip install torchgeometry","metadata":{"papermill":{"duration":158.67367,"end_time":"2023-11-16T02:22:47.989625","exception":false,"start_time":"2023-11-16T02:20:09.315955","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:09:43.260108Z","iopub.execute_input":"2023-11-17T14:09:43.260428Z","iopub.status.idle":"2023-11-17T14:10:08.880852Z","shell.execute_reply.started":"2023-11-17T14:09:43.260398Z","shell.execute_reply":"2023-11-17T14:10:08.879871Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\nCollecting torchgeometry\n  Downloading torchgeometry-0.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torchgeometry) (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchgeometry) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchgeometry) (1.3.0)\nInstalling collected packages: torchgeometry\nSuccessfully installed torchgeometry-0.1.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchsummary import summary\nfrom torchgeometry.losses import one_hot\nimport os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport cv2\nimport time\nimport imageio\nimport matplotlib.pyplot as plt\nimport time\nfrom torch.utils.data import  ConcatDataset, Dataset, DataLoader, random_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch import Tensor\nfrom torchvision.transforms import *\nfrom collections import OrderedDict\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport wandb\n","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":6.224574,"end_time":"2023-11-16T02:22:54.289648","exception":false,"start_time":"2023-11-16T02:22:48.065074","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:08.882992Z","iopub.execute_input":"2023-11-17T14:10:08.883300Z","iopub.status.idle":"2023-11-17T14:10:15.523052Z","shell.execute_reply.started":"2023-11-17T14:10:08.883271Z","shell.execute_reply":"2023-11-17T14:10:15.522139Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi -L","metadata":{"papermill":{"duration":1.062499,"end_time":"2023-11-16T02:22:55.429210","exception":false,"start_time":"2023-11-16T02:22:54.366711","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:15.524556Z","iopub.execute_input":"2023-11-17T14:10:15.524845Z","iopub.status.idle":"2023-11-17T14:10:16.507033Z","shell.execute_reply.started":"2023-11-17T14:10:15.524821Z","shell.execute_reply":"2023-11-17T14:10:16.505855Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"GPU 0: Tesla T4 (UUID: GPU-4a6398af-93fd-7cc5-d7f1-075aa03a0bd1)\nGPU 1: Tesla T4 (UUID: GPU-29ba221e-0c5e-1e73-b21b-e85079ee9ca6)\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"papermill":{"duration":0.171343,"end_time":"2023-11-16T02:22:55.831014","exception":false,"start_time":"2023-11-16T02:22:55.659671","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:16.510043Z","iopub.execute_input":"2023-11-17T14:10:16.510360Z","iopub.status.idle":"2023-11-17T14:10:16.582164Z","shell.execute_reply.started":"2023-11-17T14:10:16.510330Z","shell.execute_reply":"2023-11-17T14:10:16.581171Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"# Parameters","metadata":{"papermill":{"duration":0.073527,"end_time":"2023-11-16T02:22:55.979969","exception":false,"start_time":"2023-11-16T02:22:55.906442","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Number of class in the data set (3: neoplastic, non neoplastic, background)\nnum_classes = 3\n\n# Number of epoch\nepochs = 20\n\n# Hyperparameters for training \nlearning_rate = 2e-04\nbatch_size = 4\ndisplay_step = 50\n\n# Model path\ncheckpoint_path = '/kaggle/working/unet_model.pth'\npretrained_path = \"/kaggle/input/unet-checkpoint/unet_model.pth\"\n# Initialize lists to keep track of loss and accuracy\nloss_epoch_array = []\ntrain_accuracy = []\ntest_accuracy = []\nvalid_accuracy = []","metadata":{"papermill":{"duration":0.082384,"end_time":"2023-11-16T02:22:56.134670","exception":false,"start_time":"2023-11-16T02:22:56.052286","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:16.583405Z","iopub.execute_input":"2023-11-17T14:10:16.583734Z","iopub.status.idle":"2023-11-17T14:10:16.592170Z","shell.execute_reply.started":"2023-11-17T14:10:16.583706Z","shell.execute_reply":"2023-11-17T14:10:16.591125Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Dataloader","metadata":{"papermill":{"duration":0.073211,"end_time":"2023-11-16T02:22:56.280559","exception":false,"start_time":"2023-11-16T02:22:56.207348","status":"completed"},"tags":[]}},{"cell_type":"code","source":"transform = Compose([Resize((256, 256), interpolation=InterpolationMode.BILINEAR),\n                     PILToTensor()])\n\ntransform1  = Compose([ Resize((256, 256), interpolation=InterpolationMode.BILINEAR),\n                        RandomVerticalFlip(p=0.9),\n                       RandomAffine((20,50)),\n                       GaussianBlur(kernel_size=3),\n                        PILToTensor()])\n                   \ntransform2 = Compose([ Resize((256, 256), interpolation=InterpolationMode.BILINEAR),\n                       RandomHorizontalFlip(p=0.9),\n                       RandomRotation(degrees=20),\n                      ColorJitter(brightness=0.5, contrast=1, saturation=0.1, hue=0.5),\n                        PILToTensor()])","metadata":{"papermill":{"duration":0.085711,"end_time":"2023-11-16T02:22:56.439620","exception":false,"start_time":"2023-11-16T02:22:56.353909","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:16.593289Z","iopub.execute_input":"2023-11-17T14:10:16.593605Z","iopub.status.idle":"2023-11-17T14:10:16.604968Z","shell.execute_reply.started":"2023-11-17T14:10:16.593579Z","shell.execute_reply":"2023-11-17T14:10:16.604142Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class UNetDataClass(Dataset):\n    def __init__(self, images_path, masks_path, transform=None):\n        super(UNetDataClass, self).__init__()\n        \n        images_list = os.listdir(images_path)\n        masks_list = os.listdir(masks_path)\n        \n        images_list = [images_path + image_name for image_name in images_list]\n        masks_list = [masks_path + mask_name for mask_name in masks_list]\n        \n        self.images_list = images_list\n        self.masks_list = masks_list\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img_path = self.images_list[index]\n        mask_path = self.masks_list[index]\n        \n        # Open image and mask\n        data = Image.open(img_path)\n        label = Image.open(mask_path)\n            \n        if (self.transform):\n            data = self.transform(data) / 255\n            label = self.transform(label) / 255\n\n        \n        label = torch.where(label>0.65, 1.0, 0.0)\n        \n        label[2, :, :] = 0.0001\n        label = torch.argmax(label, 0).type(torch.int64)\n        \n        return data, label\n    \n    def __len__(self):\n        return len(self.images_list)\n\n","metadata":{"papermill":{"duration":0.085677,"end_time":"2023-11-16T02:22:56.599692","exception":false,"start_time":"2023-11-16T02:22:56.514015","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:16.606003Z","iopub.execute_input":"2023-11-17T14:10:16.606516Z","iopub.status.idle":"2023-11-17T14:10:16.617172Z","shell.execute_reply.started":"2023-11-17T14:10:16.606478Z","shell.execute_reply":"2023-11-17T14:10:16.616316Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\nmasks_path =  \"/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt/\"","metadata":{"papermill":{"duration":0.080389,"end_time":"2023-11-16T02:22:56.908141","exception":false,"start_time":"2023-11-16T02:22:56.827752","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:16.618484Z","iopub.execute_input":"2023-11-17T14:10:16.619100Z","iopub.status.idle":"2023-11-17T14:10:16.632590Z","shell.execute_reply.started":"2023-11-17T14:10:16.619040Z","shell.execute_reply":"2023-11-17T14:10:16.631649Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"original_dataset = UNetDataClass(images_path, masks_path, transform=transform)\ndataset_transform1 = UNetDataClass(images_path, masks_path, transform=transform1)\ndataset_transform2 = UNetDataClass(images_path, masks_path, transform=transform2)\n\ndataset1 = ConcatDataset([original_dataset, dataset_transform1])\nunet_dataset = ConcatDataset([dataset1, dataset_transform2])","metadata":{"papermill":{"duration":0.205315,"end_time":"2023-11-16T02:22:57.188480","exception":false,"start_time":"2023-11-16T02:22:56.983165","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:16.633853Z","iopub.execute_input":"2023-11-17T14:10:16.634257Z","iopub.status.idle":"2023-11-17T14:10:17.294159Z","shell.execute_reply.started":"2023-11-17T14:10:16.634223Z","shell.execute_reply":"2023-11-17T14:10:17.293143Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train_size = 0.9\nvalid_size = 0.1","metadata":{"papermill":{"duration":0.083156,"end_time":"2023-11-16T02:22:57.346072","exception":false,"start_time":"2023-11-16T02:22:57.262916","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:17.295452Z","iopub.execute_input":"2023-11-17T14:10:17.295765Z","iopub.status.idle":"2023-11-17T14:10:17.300217Z","shell.execute_reply.started":"2023-11-17T14:10:17.295721Z","shell.execute_reply":"2023-11-17T14:10:17.299254Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_set, valid_set = random_split(unet_dataset, \n                                    [int(train_size * len(unet_dataset)) , \n                                     int(valid_size * len(unet_dataset))])","metadata":{"papermill":{"duration":0.085587,"end_time":"2023-11-16T02:22:57.506618","exception":false,"start_time":"2023-11-16T02:22:57.421031","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:17.304709Z","iopub.execute_input":"2023-11-17T14:10:17.304995Z","iopub.status.idle":"2023-11-17T14:10:17.325494Z","shell.execute_reply.started":"2023-11-17T14:10:17.304970Z","shell.execute_reply":"2023-11-17T14:10:17.324643Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True)","metadata":{"papermill":{"duration":0.080661,"end_time":"2023-11-16T02:22:57.661766","exception":false,"start_time":"2023-11-16T02:22:57.581105","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:17.326500Z","iopub.execute_input":"2023-11-17T14:10:17.326758Z","iopub.status.idle":"2023-11-17T14:10:17.332120Z","shell.execute_reply.started":"2023-11-17T14:10:17.326735Z","shell.execute_reply":"2023-11-17T14:10:17.331131Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Loss function","metadata":{"papermill":{"duration":0.075734,"end_time":"2023-11-16T02:22:59.205513","exception":false,"start_time":"2023-11-16T02:22:59.129779","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class CEDiceLoss(nn.Module):\n    def __init__(self, weights) -> None:\n        super(CEDiceLoss, self).__init__()\n        self.eps: float = 1e-6\n        self.weights: torch.Tensor = weights\n\n    def forward(\n            self,\n            input: torch.Tensor,\n            target: torch.Tensor) -> torch.Tensor:\n        if not torch.is_tensor(input):\n            raise TypeError(\"Input type is not a torch.Tensor. Got {}\"\n                            .format(type(input)))\n        if not len(input.shape) == 4:\n            raise ValueError(\"Invalid input shape, we expect BxNxHxW. Got: {}\"\n                             .format(input.shape))\n        if not input.shape[-2:] == target.shape[-2:]:\n            raise ValueError(\"input and target shapes must be the same. Got: {}\"\n                             .format(input.shape, input.shape))\n        if not input.device == target.device:\n            raise ValueError(\n                \"input and target must be in the same device. Got: {}\" .format(\n                    input.device, target.device))\n        if not self.weights.shape[1] == input.shape[1]:\n            raise ValueError(\"The number of weights must equal the number of classes\")\n        if not torch.sum(self.weights).item() == 1:\n            raise ValueError(\"The sum of all weights must equal 1\")\n            \n        # cross entropy loss\n        celoss = nn.CrossEntropyLoss(self.weights)(input, target)\n        \n        # compute softmax over the classes axis\n        input_soft = F.softmax(input, dim=1)\n\n        # create the labels one hot tensor\n        target_one_hot = one_hot(target, num_classes=input.shape[1],\n                                 device=input.device, dtype=input.dtype)\n\n        # compute the actual dice score\n        dims = (2, 3)\n        intersection = torch.sum(input_soft * target_one_hot, dims)\n        cardinality = torch.sum(input_soft + target_one_hot, dims)\n\n        dice_score = 2. * intersection / (cardinality + self.eps)\n        \n        dice_score = torch.sum(dice_score * self.weights, dim=1)\n        \n        return torch.mean(1. - dice_score) + celoss","metadata":{"papermill":{"duration":0.089861,"end_time":"2023-11-16T02:22:59.368835","exception":false,"start_time":"2023-11-16T02:22:59.278974","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:17.333364Z","iopub.execute_input":"2023-11-17T14:10:17.333632Z","iopub.status.idle":"2023-11-17T14:10:17.347366Z","shell.execute_reply.started":"2023-11-17T14:10:17.333609Z","shell.execute_reply":"2023-11-17T14:10:17.346469Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"papermill":{"duration":0.074168,"end_time":"2023-11-16T02:22:59.519527","exception":false,"start_time":"2023-11-16T02:22:59.445359","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**Initialize weights**","metadata":{"papermill":{"duration":0.073594,"end_time":"2023-11-16T02:22:59.666936","exception":false,"start_time":"2023-11-16T02:22:59.593342","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def weights_init(model):\n    if isinstance(model, nn.Linear):\n        # Xavier Distribution\n        torch.nn.init.xavier_uniform_(model.weight)","metadata":{"papermill":{"duration":0.082127,"end_time":"2023-11-16T02:22:59.824102","exception":false,"start_time":"2023-11-16T02:22:59.741975","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:17.348621Z","iopub.execute_input":"2023-11-17T14:10:17.349471Z","iopub.status.idle":"2023-11-17T14:10:17.361344Z","shell.execute_reply.started":"2023-11-17T14:10:17.349435Z","shell.execute_reply":"2023-11-17T14:10:17.360563Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"def save_model(model, optimizer, path):\n    checkpoint = {\n        \"model\": model.state_dict(),\n        \"optimizer\": optimizer.state_dict(),\n    }\n    torch.save(checkpoint, path)\n\ndef load_model(model, optimizer, path):\n    checkpoint = torch.load(path)\n    model.load_state_dict(checkpoint[\"model\"])\n    optimizer.load_state_dict(checkpoint['optimizer'])\n    return model, optimizer","metadata":{"papermill":{"duration":0.087911,"end_time":"2023-11-16T02:22:59.988742","exception":false,"start_time":"2023-11-16T02:22:59.900831","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:17.362451Z","iopub.execute_input":"2023-11-17T14:10:17.362688Z","iopub.status.idle":"2023-11-17T14:10:17.373578Z","shell.execute_reply.started":"2023-11-17T14:10:17.362667Z","shell.execute_reply":"2023-11-17T14:10:17.372736Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**Train model**","metadata":{"papermill":{"duration":0.073663,"end_time":"2023-11-16T02:23:00.141433","exception":false,"start_time":"2023-11-16T02:23:00.067770","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Train function for each epoch\ndef train(train_dataloader, valid_dataloader,learing_rate_scheduler, epoch, display_step):\n    print(f\"Start epoch #{epoch+1}, learning rate for this epoch: {learing_rate_scheduler.get_last_lr()}\")\n    start_time = time.time()\n    train_loss_epoch = 0\n    test_loss_epoch = 0\n    last_loss = 999999999\n    model.train()\n    for i, (data,targets) in enumerate(train_dataloader):\n        \n        # Load data into GPU\n        data, targets = data.to(device), targets.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(data)\n\n        # Backpropagation, compute gradients\n        loss = loss_function(outputs, targets.long())\n        loss.backward()\n\n        # Apply gradients\n        optimizer.step()\n        \n        # Save loss\n        train_loss_epoch += loss.item()\n        if (i+1) % display_step == 0:\n#             accuracy = float(test(test_loader))\n            print('Train Epoch: {} [{}/{} ({}%)]\\tLoss: {:.4f}'.format(\n                epoch + 1, (i+1) * len(data), len(train_dataloader.dataset), 100 * (i+1) * len(data) / len(train_dataloader.dataset), \n                loss.item()))\n                  \n    print(f\"Done epoch #{epoch+1}, time for this epoch: {time.time()-start_time}s\")\n    train_loss_epoch/= (i + 1)\n    \n    # Evaluate the validation set\n    model.eval()\n    with torch.no_grad():\n        for data, target in valid_dataloader:\n            data, target = data.to(device), target.to(device)\n            test_output = model(data)\n            test_loss = loss_function(test_output, target)\n            test_loss_epoch += test_loss.item()\n            \n    test_loss_epoch/= (i+1)\n    \n    return train_loss_epoch , test_loss_epoch","metadata":{"papermill":{"duration":0.08832,"end_time":"2023-11-16T02:23:00.306577","exception":false,"start_time":"2023-11-16T02:23:00.218257","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:17.374760Z","iopub.execute_input":"2023-11-17T14:10:17.375086Z","iopub.status.idle":"2023-11-17T14:10:17.386486Z","shell.execute_reply.started":"2023-11-17T14:10:17.375062Z","shell.execute_reply":"2023-11-17T14:10:17.385672Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"!pip install -q segmentation-models-pytorch\nimport segmentation_models_pytorch as smp\n\nmodel = smp.UnetPlusPlus(\n    encoder_name='resnet50', \n    encoder_weights=\"imagenet\",     \n    in_channels=3,                  \n    classes=3     \n)\n\nmodel.apply(weights_init)\n# # model = nn.DataParallel(model)\n# checkpoint = torch.load(pretrained_path)\n\n# new_state_dict = OrderedDict()\n# for k, v in checkpoint['model'].items():\n#     name = k[7:] # remove `module.`\n#     new_state_dict[name] = v\n# # load params\n# model.load_state_dict(new_state_dict)\nmodel = nn.DataParallel(model)\nmodel.to(device)","metadata":{"papermill":{"duration":3.487095,"end_time":"2023-11-16T02:23:04.032139","exception":false,"start_time":"2023-11-16T02:23:00.545044","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:17.387620Z","iopub.execute_input":"2023-11-17T14:10:17.388467Z","iopub.status.idle":"2023-11-17T14:10:42.592005Z","shell.execute_reply.started":"2023-11-17T14:10:17.388432Z","shell.execute_reply":"2023-11-17T14:10:42.591058Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 227MB/s] \n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): UnetPlusPlus(\n    (encoder): ResNetEncoder(\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (layer1): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer2): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer3): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (4): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (5): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer4): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (relu): ReLU(inplace=True)\n        )\n      )\n    )\n    (decoder): UnetPlusPlusDecoder(\n      (center): Identity()\n      (blocks): ModuleDict(\n        (x_0_0): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(3072, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_0_1): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(1280, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_1_1): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_0_2): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(896, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_1_2): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_2_2): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_0_3): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_1_3): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(448, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_2_3): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_3_3): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n        (x_0_4): DecoderBlock(\n          (conv1): Conv2dReLU(\n            (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention1): Attention(\n            (attention): Identity()\n          )\n          (conv2): Conv2dReLU(\n            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU(inplace=True)\n          )\n          (attention2): Attention(\n            (attention): Identity()\n          )\n        )\n      )\n    )\n    (segmentation_head): SegmentationHead(\n      (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Identity()\n      (2): Activation(\n        (activation): Identity()\n      )\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"weights = torch.Tensor([[0.4, 0.55, 0.05]]).cuda()\nloss_function = CEDiceLoss(weights)\n\n# Define the optimizer (Adam optimizer)\noptimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n# optimizer.load_state_dict(checkpoint['optimizer'])\n\n# Learning rate scheduler\nlearing_rate_scheduler = lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.6)","metadata":{"papermill":{"duration":0.086632,"end_time":"2023-11-16T02:23:04.343079","exception":false,"start_time":"2023-11-16T02:23:04.256447","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:42.593738Z","iopub.execute_input":"2023-11-17T14:10:42.594611Z","iopub.status.idle":"2023-11-17T14:10:42.602057Z","shell.execute_reply.started":"2023-11-17T14:10:42.594564Z","shell.execute_reply":"2023-11-17T14:10:42.601156Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"save_model(model, optimizer, checkpoint_path)","metadata":{"papermill":{"duration":0.302901,"end_time":"2023-11-16T02:23:04.722205","exception":false,"start_time":"2023-11-16T02:23:04.419304","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:42.603400Z","iopub.execute_input":"2023-11-17T14:10:42.604013Z","iopub.status.idle":"2023-11-17T14:10:42.927771Z","shell.execute_reply.started":"2023-11-17T14:10:42.603986Z","shell.execute_reply":"2023-11-17T14:10:42.926759Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"wandb.login(\n    key = \"f49e2b5c71203e093d9349c33d5b052b8e9267e8\",\n)\nwandb.init(\n    project = \"DLassignment\"\n)\n\n# Training loop\ntrain_loss_array = []\ntest_loss_array = []\nlast_loss = 9999999999999\nfor epoch in range(epochs):\n    train_loss_epoch = 0\n    test_loss_epoch = 0\n    (train_loss_epoch, test_loss_epoch) = train(train_loader, \n                                              valid_loader, \n                                              learing_rate_scheduler, epoch, display_step)\n    \n    if test_loss_epoch < last_loss:\n        save_model(model, optimizer, checkpoint_path)\n        last_loss = test_loss_epoch\n        \n    learing_rate_scheduler.step()\n    train_loss_array.append(train_loss_epoch)\n    test_loss_array.append(test_loss_epoch)\n    wandb.log({\"Train loss\": train_loss_epoch, \"Valid loss\": test_loss_epoch})\n","metadata":{"papermill":{"duration":18311.166033,"end_time":"2023-11-16T07:28:17.719780","exception":false,"start_time":"2023-11-16T02:23:06.553747","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-11-17T14:10:42.929165Z","iopub.execute_input":"2023-11-17T14:10:42.929480Z","iopub.status.idle":"2023-11-17T15:39:25.137567Z","shell.execute_reply.started":"2023-11-17T14:10:42.929452Z","shell.execute_reply":"2023-11-17T15:39:25.136272Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnguyentrungtru\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231117_141045-9s83jgf4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nguyentrungtru/DLassignment/runs/9s83jgf4' target=\"_blank\">atomic-field-31</a></strong> to <a href='https://wandb.ai/nguyentrungtru/DLassignment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nguyentrungtru/DLassignment' target=\"_blank\">https://wandb.ai/nguyentrungtru/DLassignment</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nguyentrungtru/DLassignment/runs/9s83jgf4' target=\"_blank\">https://wandb.ai/nguyentrungtru/DLassignment/runs/9s83jgf4</a>"},"metadata":{}},{"name":"stdout","text":"Start epoch #1, learning rate for this epoch: [0.0002]\nTrain Epoch: 1 [200/2700 (7.407407407407407%)]\tLoss: 1.6331\nTrain Epoch: 1 [400/2700 (14.814814814814815%)]\tLoss: 1.4536\nTrain Epoch: 1 [600/2700 (22.22222222222222%)]\tLoss: 1.4867\nTrain Epoch: 1 [800/2700 (29.62962962962963%)]\tLoss: 1.4162\nTrain Epoch: 1 [1000/2700 (37.03703703703704%)]\tLoss: 1.4758\nTrain Epoch: 1 [1200/2700 (44.44444444444444%)]\tLoss: 1.2000\nTrain Epoch: 1 [1400/2700 (51.851851851851855%)]\tLoss: 1.0515\nTrain Epoch: 1 [1600/2700 (59.25925925925926%)]\tLoss: 1.3194\nTrain Epoch: 1 [1800/2700 (66.66666666666667%)]\tLoss: 0.9755\nTrain Epoch: 1 [2000/2700 (74.07407407407408%)]\tLoss: 1.0734\nTrain Epoch: 1 [2200/2700 (81.48148148148148%)]\tLoss: 1.0116\nTrain Epoch: 1 [2400/2700 (88.88888888888889%)]\tLoss: 1.2611\nTrain Epoch: 1 [2600/2700 (96.29629629629629%)]\tLoss: 1.1115\nDone epoch #1, time for this epoch: 271.34675431251526s\nStart epoch #2, learning rate for this epoch: [0.0002]\nTrain Epoch: 2 [200/2700 (7.407407407407407%)]\tLoss: 1.3096\nTrain Epoch: 2 [400/2700 (14.814814814814815%)]\tLoss: 1.2668\nTrain Epoch: 2 [600/2700 (22.22222222222222%)]\tLoss: 1.2121\nTrain Epoch: 2 [800/2700 (29.62962962962963%)]\tLoss: 1.1381\nTrain Epoch: 2 [1000/2700 (37.03703703703704%)]\tLoss: 1.0262\nTrain Epoch: 2 [1200/2700 (44.44444444444444%)]\tLoss: 1.0918\nTrain Epoch: 2 [1400/2700 (51.851851851851855%)]\tLoss: 0.8623\nTrain Epoch: 2 [1600/2700 (59.25925925925926%)]\tLoss: 0.9475\nTrain Epoch: 2 [1800/2700 (66.66666666666667%)]\tLoss: 1.0989\nTrain Epoch: 2 [2000/2700 (74.07407407407408%)]\tLoss: 1.0217\nTrain Epoch: 2 [2200/2700 (81.48148148148148%)]\tLoss: 1.4054\nTrain Epoch: 2 [2400/2700 (88.88888888888889%)]\tLoss: 1.3132\nTrain Epoch: 2 [2600/2700 (96.29629629629629%)]\tLoss: 1.0371\nDone epoch #2, time for this epoch: 247.66555452346802s\nStart epoch #3, learning rate for this epoch: [0.0002]\nTrain Epoch: 3 [200/2700 (7.407407407407407%)]\tLoss: 1.1959\nTrain Epoch: 3 [400/2700 (14.814814814814815%)]\tLoss: 1.1314\nTrain Epoch: 3 [600/2700 (22.22222222222222%)]\tLoss: 1.1777\nTrain Epoch: 3 [800/2700 (29.62962962962963%)]\tLoss: 1.2963\nTrain Epoch: 3 [1000/2700 (37.03703703703704%)]\tLoss: 1.4007\nTrain Epoch: 3 [1200/2700 (44.44444444444444%)]\tLoss: 1.1600\nTrain Epoch: 3 [1400/2700 (51.851851851851855%)]\tLoss: 1.2549\nTrain Epoch: 3 [1600/2700 (59.25925925925926%)]\tLoss: 1.8408\nTrain Epoch: 3 [1800/2700 (66.66666666666667%)]\tLoss: 0.9633\nTrain Epoch: 3 [2000/2700 (74.07407407407408%)]\tLoss: 1.7431\nTrain Epoch: 3 [2200/2700 (81.48148148148148%)]\tLoss: 1.0984\nTrain Epoch: 3 [2400/2700 (88.88888888888889%)]\tLoss: 1.2557\nTrain Epoch: 3 [2600/2700 (96.29629629629629%)]\tLoss: 0.9271\nDone epoch #3, time for this epoch: 245.53061628341675s\nStart epoch #4, learning rate for this epoch: [0.0002]\nTrain Epoch: 4 [200/2700 (7.407407407407407%)]\tLoss: 0.9586\nTrain Epoch: 4 [400/2700 (14.814814814814815%)]\tLoss: 1.1042\nTrain Epoch: 4 [600/2700 (22.22222222222222%)]\tLoss: 1.3075\nTrain Epoch: 4 [800/2700 (29.62962962962963%)]\tLoss: 1.0988\nTrain Epoch: 4 [1000/2700 (37.03703703703704%)]\tLoss: 1.0754\nTrain Epoch: 4 [1200/2700 (44.44444444444444%)]\tLoss: 1.0806\nTrain Epoch: 4 [1400/2700 (51.851851851851855%)]\tLoss: 1.1502\nTrain Epoch: 4 [1600/2700 (59.25925925925926%)]\tLoss: 1.1306\nTrain Epoch: 4 [1800/2700 (66.66666666666667%)]\tLoss: 1.7693\nTrain Epoch: 4 [2000/2700 (74.07407407407408%)]\tLoss: 1.2414\nTrain Epoch: 4 [2200/2700 (81.48148148148148%)]\tLoss: 0.9260\nTrain Epoch: 4 [2400/2700 (88.88888888888889%)]\tLoss: 1.0197\nTrain Epoch: 4 [2600/2700 (96.29629629629629%)]\tLoss: 1.2146\nDone epoch #4, time for this epoch: 245.88448643684387s\nStart epoch #5, learning rate for this epoch: [0.00012]\nTrain Epoch: 5 [200/2700 (7.407407407407407%)]\tLoss: 0.9902\nTrain Epoch: 5 [400/2700 (14.814814814814815%)]\tLoss: 0.9018\nTrain Epoch: 5 [600/2700 (22.22222222222222%)]\tLoss: 1.1837\nTrain Epoch: 5 [800/2700 (29.62962962962963%)]\tLoss: 1.0531\nTrain Epoch: 5 [1000/2700 (37.03703703703704%)]\tLoss: 1.0187\nTrain Epoch: 5 [1200/2700 (44.44444444444444%)]\tLoss: 0.8969\nTrain Epoch: 5 [1400/2700 (51.851851851851855%)]\tLoss: 0.9149\nTrain Epoch: 5 [1600/2700 (59.25925925925926%)]\tLoss: 1.0015\nTrain Epoch: 5 [1800/2700 (66.66666666666667%)]\tLoss: 1.1375\nTrain Epoch: 5 [2000/2700 (74.07407407407408%)]\tLoss: 1.0601\nTrain Epoch: 5 [2200/2700 (81.48148148148148%)]\tLoss: 1.7438\nTrain Epoch: 5 [2400/2700 (88.88888888888889%)]\tLoss: 1.1027\nTrain Epoch: 5 [2600/2700 (96.29629629629629%)]\tLoss: 0.8766\nDone epoch #5, time for this epoch: 245.54299092292786s\nStart epoch #6, learning rate for this epoch: [0.00012]\nTrain Epoch: 6 [200/2700 (7.407407407407407%)]\tLoss: 1.0058\nTrain Epoch: 6 [400/2700 (14.814814814814815%)]\tLoss: 0.8235\nTrain Epoch: 6 [600/2700 (22.22222222222222%)]\tLoss: 0.8664\nTrain Epoch: 6 [800/2700 (29.62962962962963%)]\tLoss: 0.9157\nTrain Epoch: 6 [1000/2700 (37.03703703703704%)]\tLoss: 1.0042\nTrain Epoch: 6 [1200/2700 (44.44444444444444%)]\tLoss: 1.0337\nTrain Epoch: 6 [1400/2700 (51.851851851851855%)]\tLoss: 0.7651\nTrain Epoch: 6 [1600/2700 (59.25925925925926%)]\tLoss: 1.0417\nTrain Epoch: 6 [1800/2700 (66.66666666666667%)]\tLoss: 0.7417\nTrain Epoch: 6 [2000/2700 (74.07407407407408%)]\tLoss: 0.8422\nTrain Epoch: 6 [2200/2700 (81.48148148148148%)]\tLoss: 1.3748\nTrain Epoch: 6 [2400/2700 (88.88888888888889%)]\tLoss: 0.9054\nTrain Epoch: 6 [2600/2700 (96.29629629629629%)]\tLoss: 1.3713\nDone epoch #6, time for this epoch: 247.4259147644043s\nStart epoch #7, learning rate for this epoch: [0.00012]\nTrain Epoch: 7 [200/2700 (7.407407407407407%)]\tLoss: 1.0414\nTrain Epoch: 7 [400/2700 (14.814814814814815%)]\tLoss: 1.5988\nTrain Epoch: 7 [600/2700 (22.22222222222222%)]\tLoss: 1.1859\nTrain Epoch: 7 [800/2700 (29.62962962962963%)]\tLoss: 0.9899\nTrain Epoch: 7 [1000/2700 (37.03703703703704%)]\tLoss: 0.8505\nTrain Epoch: 7 [1200/2700 (44.44444444444444%)]\tLoss: 1.2116\nTrain Epoch: 7 [1400/2700 (51.851851851851855%)]\tLoss: 0.8404\nTrain Epoch: 7 [1600/2700 (59.25925925925926%)]\tLoss: 1.0917\nTrain Epoch: 7 [1800/2700 (66.66666666666667%)]\tLoss: 1.1911\nTrain Epoch: 7 [2000/2700 (74.07407407407408%)]\tLoss: 0.7643\nTrain Epoch: 7 [2200/2700 (81.48148148148148%)]\tLoss: 1.1257\nTrain Epoch: 7 [2400/2700 (88.88888888888889%)]\tLoss: 0.8952\nTrain Epoch: 7 [2600/2700 (96.29629629629629%)]\tLoss: 0.8605\nDone epoch #7, time for this epoch: 244.61721324920654s\nStart epoch #8, learning rate for this epoch: [0.00012]\nTrain Epoch: 8 [200/2700 (7.407407407407407%)]\tLoss: 0.8860\nTrain Epoch: 8 [400/2700 (14.814814814814815%)]\tLoss: 1.2930\nTrain Epoch: 8 [600/2700 (22.22222222222222%)]\tLoss: 0.6967\nTrain Epoch: 8 [800/2700 (29.62962962962963%)]\tLoss: 0.9570\nTrain Epoch: 8 [1000/2700 (37.03703703703704%)]\tLoss: 1.1335\nTrain Epoch: 8 [1200/2700 (44.44444444444444%)]\tLoss: 1.3323\nTrain Epoch: 8 [1400/2700 (51.851851851851855%)]\tLoss: 0.9681\nTrain Epoch: 8 [1600/2700 (59.25925925925926%)]\tLoss: 0.8866\nTrain Epoch: 8 [1800/2700 (66.66666666666667%)]\tLoss: 1.1017\nTrain Epoch: 8 [2000/2700 (74.07407407407408%)]\tLoss: 1.1563\nTrain Epoch: 8 [2200/2700 (81.48148148148148%)]\tLoss: 1.0091\nTrain Epoch: 8 [2400/2700 (88.88888888888889%)]\tLoss: 1.0707\nTrain Epoch: 8 [2600/2700 (96.29629629629629%)]\tLoss: 1.2056\nDone epoch #8, time for this epoch: 244.84488821029663s\nStart epoch #9, learning rate for this epoch: [7.2e-05]\nTrain Epoch: 9 [200/2700 (7.407407407407407%)]\tLoss: 0.9905\nTrain Epoch: 9 [400/2700 (14.814814814814815%)]\tLoss: 0.8973\nTrain Epoch: 9 [600/2700 (22.22222222222222%)]\tLoss: 1.4849\nTrain Epoch: 9 [800/2700 (29.62962962962963%)]\tLoss: 1.2746\nTrain Epoch: 9 [1000/2700 (37.03703703703704%)]\tLoss: 0.8456\nTrain Epoch: 9 [1200/2700 (44.44444444444444%)]\tLoss: 0.8356\nTrain Epoch: 9 [1400/2700 (51.851851851851855%)]\tLoss: 0.9131\nTrain Epoch: 9 [1600/2700 (59.25925925925926%)]\tLoss: 0.8128\nTrain Epoch: 9 [1800/2700 (66.66666666666667%)]\tLoss: 0.9581\nTrain Epoch: 9 [2000/2700 (74.07407407407408%)]\tLoss: 1.3756\nTrain Epoch: 9 [2200/2700 (81.48148148148148%)]\tLoss: 1.4716\nTrain Epoch: 9 [2400/2700 (88.88888888888889%)]\tLoss: 1.0265\nTrain Epoch: 9 [2600/2700 (96.29629629629629%)]\tLoss: 0.9546\nDone epoch #9, time for this epoch: 243.86541652679443s\nStart epoch #10, learning rate for this epoch: [7.2e-05]\nTrain Epoch: 10 [200/2700 (7.407407407407407%)]\tLoss: 0.9512\nTrain Epoch: 10 [400/2700 (14.814814814814815%)]\tLoss: 1.0491\nTrain Epoch: 10 [600/2700 (22.22222222222222%)]\tLoss: 0.8715\nTrain Epoch: 10 [800/2700 (29.62962962962963%)]\tLoss: 1.0561\nTrain Epoch: 10 [1000/2700 (37.03703703703704%)]\tLoss: 0.9821\nTrain Epoch: 10 [1200/2700 (44.44444444444444%)]\tLoss: 1.0425\nTrain Epoch: 10 [1400/2700 (51.851851851851855%)]\tLoss: 1.3642\nTrain Epoch: 10 [1600/2700 (59.25925925925926%)]\tLoss: 0.8996\nTrain Epoch: 10 [1800/2700 (66.66666666666667%)]\tLoss: 0.7548\nTrain Epoch: 10 [2000/2700 (74.07407407407408%)]\tLoss: 0.9093\nTrain Epoch: 10 [2200/2700 (81.48148148148148%)]\tLoss: 0.9433\nTrain Epoch: 10 [2400/2700 (88.88888888888889%)]\tLoss: 1.9936\nTrain Epoch: 10 [2600/2700 (96.29629629629629%)]\tLoss: 0.9417\nDone epoch #10, time for this epoch: 243.21805262565613s\nStart epoch #11, learning rate for this epoch: [7.2e-05]\nTrain Epoch: 11 [200/2700 (7.407407407407407%)]\tLoss: 0.8919\nTrain Epoch: 11 [400/2700 (14.814814814814815%)]\tLoss: 1.3376\nTrain Epoch: 11 [600/2700 (22.22222222222222%)]\tLoss: 0.7573\nTrain Epoch: 11 [800/2700 (29.62962962962963%)]\tLoss: 0.9454\nTrain Epoch: 11 [1000/2700 (37.03703703703704%)]\tLoss: 1.0392\nTrain Epoch: 11 [1200/2700 (44.44444444444444%)]\tLoss: 1.1598\nTrain Epoch: 11 [1400/2700 (51.851851851851855%)]\tLoss: 0.8026\nTrain Epoch: 11 [1600/2700 (59.25925925925926%)]\tLoss: 0.9278\nTrain Epoch: 11 [1800/2700 (66.66666666666667%)]\tLoss: 0.8776\nTrain Epoch: 11 [2000/2700 (74.07407407407408%)]\tLoss: 1.1007\nTrain Epoch: 11 [2200/2700 (81.48148148148148%)]\tLoss: 1.2221\nTrain Epoch: 11 [2400/2700 (88.88888888888889%)]\tLoss: 1.1401\nTrain Epoch: 11 [2600/2700 (96.29629629629629%)]\tLoss: 1.0148\nDone epoch #11, time for this epoch: 242.74907898902893s\nStart epoch #12, learning rate for this epoch: [7.2e-05]\nTrain Epoch: 12 [200/2700 (7.407407407407407%)]\tLoss: 1.1626\nTrain Epoch: 12 [400/2700 (14.814814814814815%)]\tLoss: 0.9087\nTrain Epoch: 12 [600/2700 (22.22222222222222%)]\tLoss: 0.7104\nTrain Epoch: 12 [800/2700 (29.62962962962963%)]\tLoss: 1.1653\nTrain Epoch: 12 [1000/2700 (37.03703703703704%)]\tLoss: 0.9789\nTrain Epoch: 12 [1200/2700 (44.44444444444444%)]\tLoss: 0.9582\nTrain Epoch: 12 [1400/2700 (51.851851851851855%)]\tLoss: 0.8850\nTrain Epoch: 12 [1600/2700 (59.25925925925926%)]\tLoss: 0.8808\nTrain Epoch: 12 [1800/2700 (66.66666666666667%)]\tLoss: 1.0009\nTrain Epoch: 12 [2000/2700 (74.07407407407408%)]\tLoss: 1.2704\nTrain Epoch: 12 [2200/2700 (81.48148148148148%)]\tLoss: 1.0043\nTrain Epoch: 12 [2400/2700 (88.88888888888889%)]\tLoss: 1.1275\nTrain Epoch: 12 [2600/2700 (96.29629629629629%)]\tLoss: 0.6770\nDone epoch #12, time for this epoch: 243.93131351470947s\nStart epoch #13, learning rate for this epoch: [4.32e-05]\nTrain Epoch: 13 [200/2700 (7.407407407407407%)]\tLoss: 0.8013\nTrain Epoch: 13 [400/2700 (14.814814814814815%)]\tLoss: 0.9040\nTrain Epoch: 13 [600/2700 (22.22222222222222%)]\tLoss: 0.9393\nTrain Epoch: 13 [800/2700 (29.62962962962963%)]\tLoss: 0.9332\nTrain Epoch: 13 [1000/2700 (37.03703703703704%)]\tLoss: 0.8716\nTrain Epoch: 13 [1200/2700 (44.44444444444444%)]\tLoss: 0.9142\nTrain Epoch: 13 [1400/2700 (51.851851851851855%)]\tLoss: 1.2177\nTrain Epoch: 13 [1600/2700 (59.25925925925926%)]\tLoss: 0.6838\nTrain Epoch: 13 [1800/2700 (66.66666666666667%)]\tLoss: 0.9452\nTrain Epoch: 13 [2000/2700 (74.07407407407408%)]\tLoss: 0.9790\nTrain Epoch: 13 [2200/2700 (81.48148148148148%)]\tLoss: 1.0663\nTrain Epoch: 13 [2400/2700 (88.88888888888889%)]\tLoss: 0.8695\nTrain Epoch: 13 [2600/2700 (96.29629629629629%)]\tLoss: 1.4936\nDone epoch #13, time for this epoch: 244.68110370635986s\nStart epoch #14, learning rate for this epoch: [4.32e-05]\nTrain Epoch: 14 [200/2700 (7.407407407407407%)]\tLoss: 0.8662\nTrain Epoch: 14 [400/2700 (14.814814814814815%)]\tLoss: 0.7704\nTrain Epoch: 14 [600/2700 (22.22222222222222%)]\tLoss: 1.0013\nTrain Epoch: 14 [800/2700 (29.62962962962963%)]\tLoss: 0.6682\nTrain Epoch: 14 [1000/2700 (37.03703703703704%)]\tLoss: 0.6818\nTrain Epoch: 14 [1200/2700 (44.44444444444444%)]\tLoss: 0.5962\nTrain Epoch: 14 [1400/2700 (51.851851851851855%)]\tLoss: 1.1942\nTrain Epoch: 14 [1600/2700 (59.25925925925926%)]\tLoss: 0.9681\nTrain Epoch: 14 [1800/2700 (66.66666666666667%)]\tLoss: 0.9272\nTrain Epoch: 14 [2000/2700 (74.07407407407408%)]\tLoss: 0.8504\nTrain Epoch: 14 [2200/2700 (81.48148148148148%)]\tLoss: 0.6928\nTrain Epoch: 14 [2400/2700 (88.88888888888889%)]\tLoss: 0.6212\nTrain Epoch: 14 [2600/2700 (96.29629629629629%)]\tLoss: 1.5192\nDone epoch #14, time for this epoch: 244.2235836982727s\nStart epoch #15, learning rate for this epoch: [4.32e-05]\nTrain Epoch: 15 [200/2700 (7.407407407407407%)]\tLoss: 0.8273\nTrain Epoch: 15 [400/2700 (14.814814814814815%)]\tLoss: 0.8394\nTrain Epoch: 15 [600/2700 (22.22222222222222%)]\tLoss: 0.9645\nTrain Epoch: 15 [800/2700 (29.62962962962963%)]\tLoss: 0.8728\nTrain Epoch: 15 [1000/2700 (37.03703703703704%)]\tLoss: 0.8113\nTrain Epoch: 15 [1200/2700 (44.44444444444444%)]\tLoss: 0.8560\nTrain Epoch: 15 [1400/2700 (51.851851851851855%)]\tLoss: 0.4980\nTrain Epoch: 15 [1600/2700 (59.25925925925926%)]\tLoss: 0.8987\nTrain Epoch: 15 [1800/2700 (66.66666666666667%)]\tLoss: 0.9940\nTrain Epoch: 15 [2000/2700 (74.07407407407408%)]\tLoss: 0.9171\nTrain Epoch: 15 [2200/2700 (81.48148148148148%)]\tLoss: 0.9497\nTrain Epoch: 15 [2400/2700 (88.88888888888889%)]\tLoss: 1.0814\nTrain Epoch: 15 [2600/2700 (96.29629629629629%)]\tLoss: 1.1401\nDone epoch #15, time for this epoch: 243.7053360939026s\nStart epoch #16, learning rate for this epoch: [4.32e-05]\nTrain Epoch: 16 [200/2700 (7.407407407407407%)]\tLoss: 0.7638\nTrain Epoch: 16 [400/2700 (14.814814814814815%)]\tLoss: 0.8127\nTrain Epoch: 16 [600/2700 (22.22222222222222%)]\tLoss: 1.4608\nTrain Epoch: 16 [800/2700 (29.62962962962963%)]\tLoss: 1.0766\nTrain Epoch: 16 [1000/2700 (37.03703703703704%)]\tLoss: 0.7346\nTrain Epoch: 16 [1200/2700 (44.44444444444444%)]\tLoss: 0.7692\nTrain Epoch: 16 [1400/2700 (51.851851851851855%)]\tLoss: 0.8298\nTrain Epoch: 16 [1600/2700 (59.25925925925926%)]\tLoss: 0.8959\nTrain Epoch: 16 [1800/2700 (66.66666666666667%)]\tLoss: 1.0279\nTrain Epoch: 16 [2000/2700 (74.07407407407408%)]\tLoss: 1.3610\nTrain Epoch: 16 [2200/2700 (81.48148148148148%)]\tLoss: 1.0984\nTrain Epoch: 16 [2400/2700 (88.88888888888889%)]\tLoss: 0.7345\nTrain Epoch: 16 [2600/2700 (96.29629629629629%)]\tLoss: 0.8759\nDone epoch #16, time for this epoch: 243.94577050209045s\nStart epoch #17, learning rate for this epoch: [2.592e-05]\nTrain Epoch: 17 [200/2700 (7.407407407407407%)]\tLoss: 0.9300\nTrain Epoch: 17 [400/2700 (14.814814814814815%)]\tLoss: 0.8598\nTrain Epoch: 17 [600/2700 (22.22222222222222%)]\tLoss: 0.8620\nTrain Epoch: 17 [800/2700 (29.62962962962963%)]\tLoss: 0.7086\nTrain Epoch: 17 [1000/2700 (37.03703703703704%)]\tLoss: 0.8392\nTrain Epoch: 17 [1200/2700 (44.44444444444444%)]\tLoss: 0.9917\nTrain Epoch: 17 [1400/2700 (51.851851851851855%)]\tLoss: 0.9638\nTrain Epoch: 17 [1600/2700 (59.25925925925926%)]\tLoss: 0.6563\nTrain Epoch: 17 [1800/2700 (66.66666666666667%)]\tLoss: 0.7194\nTrain Epoch: 17 [2000/2700 (74.07407407407408%)]\tLoss: 0.8957\nTrain Epoch: 17 [2200/2700 (81.48148148148148%)]\tLoss: 0.7842\nTrain Epoch: 17 [2400/2700 (88.88888888888889%)]\tLoss: 0.9384\nTrain Epoch: 17 [2600/2700 (96.29629629629629%)]\tLoss: 0.9011\nDone epoch #17, time for this epoch: 244.71593260765076s\nStart epoch #18, learning rate for this epoch: [2.592e-05]\nTrain Epoch: 18 [200/2700 (7.407407407407407%)]\tLoss: 0.9194\nTrain Epoch: 18 [400/2700 (14.814814814814815%)]\tLoss: 0.8041\nTrain Epoch: 18 [600/2700 (22.22222222222222%)]\tLoss: 0.9937\nTrain Epoch: 18 [800/2700 (29.62962962962963%)]\tLoss: 1.1855\nTrain Epoch: 18 [1000/2700 (37.03703703703704%)]\tLoss: 0.9945\nTrain Epoch: 18 [1200/2700 (44.44444444444444%)]\tLoss: 0.8610\nTrain Epoch: 18 [1400/2700 (51.851851851851855%)]\tLoss: 0.8468\nTrain Epoch: 18 [1600/2700 (59.25925925925926%)]\tLoss: 0.7025\nTrain Epoch: 18 [1800/2700 (66.66666666666667%)]\tLoss: 0.6158\nTrain Epoch: 18 [2000/2700 (74.07407407407408%)]\tLoss: 0.8675\nTrain Epoch: 18 [2200/2700 (81.48148148148148%)]\tLoss: 1.8779\nTrain Epoch: 18 [2400/2700 (88.88888888888889%)]\tLoss: 0.7573\nTrain Epoch: 18 [2600/2700 (96.29629629629629%)]\tLoss: 1.3990\nDone epoch #18, time for this epoch: 246.94039702415466s\nStart epoch #19, learning rate for this epoch: [2.592e-05]\nTrain Epoch: 19 [200/2700 (7.407407407407407%)]\tLoss: 0.7717\nTrain Epoch: 19 [400/2700 (14.814814814814815%)]\tLoss: 0.8070\nTrain Epoch: 19 [600/2700 (22.22222222222222%)]\tLoss: 0.6469\nTrain Epoch: 19 [800/2700 (29.62962962962963%)]\tLoss: 0.9454\nTrain Epoch: 19 [1000/2700 (37.03703703703704%)]\tLoss: 1.0472\nTrain Epoch: 19 [1200/2700 (44.44444444444444%)]\tLoss: 1.4750\nTrain Epoch: 19 [1400/2700 (51.851851851851855%)]\tLoss: 0.7704\nTrain Epoch: 19 [1600/2700 (59.25925925925926%)]\tLoss: 0.8585\nTrain Epoch: 19 [1800/2700 (66.66666666666667%)]\tLoss: 0.8666\nTrain Epoch: 19 [2000/2700 (74.07407407407408%)]\tLoss: 0.8053\nTrain Epoch: 19 [2200/2700 (81.48148148148148%)]\tLoss: 0.5666\nTrain Epoch: 19 [2400/2700 (88.88888888888889%)]\tLoss: 0.7706\nTrain Epoch: 19 [2600/2700 (96.29629629629629%)]\tLoss: 0.8539\nDone epoch #19, time for this epoch: 245.89995646476746s\nStart epoch #20, learning rate for this epoch: [2.592e-05]\nTrain Epoch: 20 [200/2700 (7.407407407407407%)]\tLoss: 0.9471\nTrain Epoch: 20 [400/2700 (14.814814814814815%)]\tLoss: 0.7293\nTrain Epoch: 20 [600/2700 (22.22222222222222%)]\tLoss: 0.7855\nTrain Epoch: 20 [800/2700 (29.62962962962963%)]\tLoss: 0.8617\nTrain Epoch: 20 [1000/2700 (37.03703703703704%)]\tLoss: 1.2491\nTrain Epoch: 20 [1200/2700 (44.44444444444444%)]\tLoss: 1.2118\nTrain Epoch: 20 [1400/2700 (51.851851851851855%)]\tLoss: 0.9381\nTrain Epoch: 20 [1600/2700 (59.25925925925926%)]\tLoss: 0.7413\nTrain Epoch: 20 [1800/2700 (66.66666666666667%)]\tLoss: 0.7765\nTrain Epoch: 20 [2000/2700 (74.07407407407408%)]\tLoss: 0.7122\nTrain Epoch: 20 [2200/2700 (81.48148148148148%)]\tLoss: 2.0648\nTrain Epoch: 20 [2400/2700 (88.88888888888889%)]\tLoss: 0.9749\nTrain Epoch: 20 [2600/2700 (96.29629629629629%)]\tLoss: 0.9311\nDone epoch #20, time for this epoch: 245.83621406555176s\n","output_type":"stream"}]},{"cell_type":"code","source":"\n\ndef rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 0] = 255\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    \n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    return rle_to_string(rle)\n\ndef rle2mask(mask_rle, shape=(3,3)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n\ndef mask2string(dir):\n    ## mask --> string\n    strings = []\n    ids = []\n    ws, hs = [[] for i in range(2)]\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n        print(path)\n        img = cv2.imread(path)[:,:,::-1]\n        h, w = img.shape[0], img.shape[1]\n        for channel in range(2):\n            ws.append(w)\n            hs.append(h)\n            ids.append(f'{id}_{channel}')\n            string = rle_encode_one_mask(img[:,:,channel])\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T15:39:25.139117Z","iopub.execute_input":"2023-11-17T15:39:25.139530Z","iopub.status.idle":"2023-11-17T15:39:25.158716Z","shell.execute_reply.started":"2023-11-17T15:39:25.139486Z","shell.execute_reply":"2023-11-17T15:39:25.157655Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"\n\nclass UNetTestDataClass(Dataset):\n    def __init__(self, images_path, transform):\n        super(UNetTestDataClass, self).__init__()\n        \n        images_list = os.listdir(images_path)\n        images_list = [images_path+i for i in images_list]\n        \n        self.images_list = images_list\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        img_path = self.images_list[index]\n        data = Image.open(img_path)\n        h = data.size[1]\n        w = data.size[0]\n        data = self.transform(data) / 255        \n        return data, img_path, h, w\n    \n    def __len__(self):\n        return len(self.images_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T15:39:25.160557Z","iopub.execute_input":"2023-11-17T15:39:25.160908Z","iopub.status.idle":"2023-11-17T15:39:25.178631Z","shell.execute_reply.started":"2023-11-17T15:39:25.160873Z","shell.execute_reply":"2023-11-17T15:39:25.177784Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"\nfrom collections import OrderedDict\nimport segmentation_models_pytorch as smp\nfrom collections import OrderedDict\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = smp.UnetPlusPlus(\n    encoder_name='resnet50', \n    encoder_weights=\"imagenet\",     \n    in_channels=3,                  \n    classes=3     \n)\n\ncheckpoint = torch.load('unet_model.pth')\n\nnew_state_dict = OrderedDict()\nfor k, v in checkpoint['model'].items():\n    name = k[7:] # remove `module.`\n    new_state_dict[name] = v\n# load params\nmodel.load_state_dict(new_state_dict)\n\n\n\ntransform = Compose([Resize((256, 256), interpolation=InterpolationMode.BILINEAR),\n                     PILToTensor()]) \n\n\ntest_path = '/kaggle/input/bkai-igh-neopolyp/test/test/'\nunet_test_dataset = UNetTestDataClass(test_path, transform)\ntest_dataloader = DataLoader(unet_test_dataset, batch_size=8, shuffle=True)\n\n\nmodel.eval()\nif not os.path.isdir(\"/kaggle/working/predicted_masks\"):\n    os.mkdir(\"/kaggle/working/predicted_masks\")\nfor _, (img, path, H, W) in enumerate(test_dataloader):\n    a = path\n    b = img\n    h = H\n    w = W\n    \n    with torch.no_grad():\n        predicted_mask = model(b)\n    for i in range(len(a)):\n        image_id = a[i].split('/')[-1].split('.')[0]\n        filename = image_id + \".png\"\n        mask2img = Resize((h[i].item(), w[i].item()), interpolation=InterpolationMode.NEAREST)(ToPILImage()(F.one_hot(torch.argmax(predicted_mask[i], 0)).permute(2, 0, 1).float()))\n        mask2img.save(os.path.join(\"/kaggle/working/predicted_masks/\", filename))\n\n\nMASK_DIR_PATH = '/kaggle/working/predicted_masks' \ndir = MASK_DIR_PATH\nres = mask2string(dir)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\ndf.to_csv(r'output.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T15:39:25.180125Z","iopub.execute_input":"2023-11-17T15:39:25.180487Z","iopub.status.idle":"2023-11-17T15:42:48.346207Z","shell.execute_reply.started":"2023-11-17T15:39:25.180453Z","shell.execute_reply":"2023-11-17T15:42:48.345150Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"/kaggle/working/predicted_masks/e56a6d9ba9d45c3dbc695325ded465ef.png\n/kaggle/working/predicted_masks/d3694abb47953b0e4909384b57bb6a05.png\n/kaggle/working/predicted_masks/395e56a6d9ba9d45c3dbc695325ded46.png\n/kaggle/working/predicted_masks/05734fbeedd0f9da760db74a29abdb04.png\n/kaggle/working/predicted_masks/d694539ef2424a9218697283baa3657e.png\n/kaggle/working/predicted_masks/66e057db382b8564872a27301a654864.png\n/kaggle/working/predicted_masks/7ad1cf2eb9d32a3dc907950289e976c7.png\n/kaggle/working/predicted_masks/6f67b5df7cdf3f33c3ca4d5060a633a8.png\n/kaggle/working/predicted_masks/be86f03d900fd197cd955fa095f97845.png\n/kaggle/working/predicted_masks/e7998934d417cb2eb1ef57af2ed9fbb6.png\n/kaggle/working/predicted_masks/a6d9ba9d45c3dbc695325ded465efde9.png\n/kaggle/working/predicted_masks/98da48d679d7c7c8d3d96fb2b87fbbcf.png\n/kaggle/working/predicted_masks/1b62f15ec83b97bb11e8e0c4416c1931.png\n/kaggle/working/predicted_masks/80cae6daedd989517cb8041ed86e5822.png\n/kaggle/working/predicted_masks/7f32574d6c748c41743c6c08a1d1ad8f.png\n/kaggle/working/predicted_masks/5beb48f0be11d0309d1dff09b8405734.png\n/kaggle/working/predicted_masks/39dda50f954ba59c7de13a35276a4764.png\n/kaggle/working/predicted_masks/15fc656702fa602bb3c7abacdbd7e6af.png\n/kaggle/working/predicted_masks/a3657e4314fe384eb2ba3adfda6c1899.png\n/kaggle/working/predicted_masks/f7fdb2d45b21960c94b0aab4c024a573.png\n/kaggle/working/predicted_masks/cb1b387133b51209db6dcdda5cc8a788.png\n/kaggle/working/predicted_masks/a15fc656702fa602bb3c7abacdbd7e6a.png\n/kaggle/working/predicted_masks/782707d7c359e27888daefee82519763.png\n/kaggle/working/predicted_masks/1209db6dcdda5cc8a788edaeb6aa460a.png\n/kaggle/working/predicted_masks/559c7e610b1531871f2fd85a04faeeb2.png\n/kaggle/working/predicted_masks/318ecf467d7ad048df39beb176363408.png\n/kaggle/working/predicted_masks/68d4b4ef4d95ceea11957998906d3694.png\n/kaggle/working/predicted_masks/e4a17af18f72c8e6166a915669c99390.png\n/kaggle/working/predicted_masks/f14e1e0ae936de314f2d95e6c487ffa6.png\n/kaggle/working/predicted_masks/c5a0808bee60b246359c68c836f843dc.png\n/kaggle/working/predicted_masks/df366e057db382b8564872a27301a654.png\n/kaggle/working/predicted_masks/6d3694abb47953b0e4909384b57bb6a0.png\n/kaggle/working/predicted_masks/9c7976c1182df0de51d32128c358d1fd.png\n/kaggle/working/predicted_masks/e3c84417fda8019410b1fcf0625f608b.png\n/kaggle/working/predicted_masks/db5eb2a0e4b50889d874c68c030b9afe.png\n/kaggle/working/predicted_masks/2cd066b9fdbc3bbc04a3afe1f119f21b.png\n/kaggle/working/predicted_masks/3c84417fda8019410b1fcf0625f608b4.png\n/kaggle/working/predicted_masks/6ad1468996b4a9ce6d840b53a6558038.png\n/kaggle/working/predicted_masks/3657e4314fe384eb2ba3adfda6c1899f.png\n/kaggle/working/predicted_masks/9fc7330398846f67b5df7cdf3f33c3ca.png\n/kaggle/working/predicted_masks/1531871f2fd85a04faeeb2b535797395.png\n/kaggle/working/predicted_masks/dd78294679c9cbb2a365b5574868eb60.png\n/kaggle/working/predicted_masks/82ea2c193ac8d551c149b60f2965341c.png\n/kaggle/working/predicted_masks/5a51625559c7e610b1531871f2fd85a0.png\n/kaggle/working/predicted_masks/7cdf3f33c3ca4d5060a633a8d5b2b2b5.png\n/kaggle/working/predicted_masks/9632a3c6f7f7fb2a643f15bd0249ddcc.png\n/kaggle/working/predicted_masks/268d4b4ef4d95ceea11957998906d369.png\n/kaggle/working/predicted_masks/c7e610b1531871f2fd85a04faeeb2b53.png\n/kaggle/working/predicted_masks/54ba59c7de13a35276a476420655433a.png\n/kaggle/working/predicted_masks/85a04faeeb2b535797395305af926a6f.png\n/kaggle/working/predicted_masks/710d568df17586ad8f3297c819c90895.png\n/kaggle/working/predicted_masks/019410b1fcf0625f608b4ce97629ab55.png\n/kaggle/working/predicted_masks/41ed86e58224cb76a67d4dcf9596154e.png\n/kaggle/working/predicted_masks/bec33b5e3d68f9d4c331587f9b9d49e2.png\n/kaggle/working/predicted_masks/8fa8625605da2023387fd56c04414eaa.png\n/kaggle/working/predicted_masks/eff05dec1eb3a70b145a7d8d3b6c0ed7.png\n/kaggle/working/predicted_masks/77e004e8bfb905b78a91391adc0bb223.png\n/kaggle/working/predicted_masks/936de314f2d95e6c487ffa651b477422.png\n/kaggle/working/predicted_masks/7b5df7cdf3f33c3ca4d5060a633a8d5b.png\n/kaggle/working/predicted_masks/ca4d5060a633a8d5b2b2b55157b7781e.png\n/kaggle/working/predicted_masks/3c692195f853af7f8a4df1ec859759b7.png\n/kaggle/working/predicted_masks/692195f853af7f8a4df1ec859759b7c8.png\n/kaggle/working/predicted_masks/4ef4d95ceea11957998906d3694abb47.png\n/kaggle/working/predicted_masks/0619ebebe9e9c9d00a4262b4fe4a5a95.png\n/kaggle/working/predicted_masks/cb2eb1ef57af2ed9fbb63b28163a7459.png\n/kaggle/working/predicted_masks/67d4dcf9596154efb7cef748d9cbd617.png\n/kaggle/working/predicted_masks/a6a4248a41e8db8b4ed633b456aaafac.png\n/kaggle/working/predicted_masks/c193ac8d551c149b60f2965341caf528.png\n/kaggle/working/predicted_masks/aeeb2b535797395305af926a6f23c5d6.png\n/kaggle/working/predicted_masks/fe1f119f21b248d152b672ab3492fc62.png\n/kaggle/working/predicted_masks/97e1c0e9082ea2c193ac8d551c149b60.png\n/kaggle/working/predicted_masks/391adc0bb223c4eaf3372eae567c94ea.png\n/kaggle/working/predicted_masks/0af3feff05dec1eb3a70b145a7d8d3b6.png\n/kaggle/working/predicted_masks/a9d45c3dbc695325ded465efde988dfb.png\n/kaggle/working/predicted_masks/4417fda8019410b1fcf0625f608b4ce9.png\n/kaggle/working/predicted_masks/c22268d4b4ef4d95ceea11957998906d.png\n/kaggle/working/predicted_masks/dc0bb223c4eaf3372eae567c94ea04c6.png\n/kaggle/working/predicted_masks/4c1711b62f15ec83b97bb11e8e0c4416.png\n/kaggle/working/predicted_masks/6240619ebebe9e9c9d00a4262b4fe4a5.png\n/kaggle/working/predicted_masks/425b976973f13dd311a65d2b46d0a608.png\n/kaggle/working/predicted_masks/05b78a91391adc0bb223c4eaf3372eae.png\n/kaggle/working/predicted_masks/3bbc04a3afe1f119f21b248d152b672a.png\n/kaggle/working/predicted_masks/7cb2eb1ef57af2ed9fbb63b28163a745.png\n/kaggle/working/predicted_masks/60b246359c68c836f843dcf41f4dce3c.png\n/kaggle/working/predicted_masks/faef7fdb2d45b21960c94b0aab4c024a.png\n/kaggle/working/predicted_masks/c4be73749a0d21db70dd094a7f32574d.png\n/kaggle/working/predicted_masks/1ad4f13ccf1f4b331a412fc44655fb51.png\n/kaggle/working/predicted_masks/626650908b1cb932a767bf5487ced51b.png\n/kaggle/working/predicted_masks/ff55177a34fc01019eec999fd84e679b.png\n/kaggle/working/predicted_masks/d5060a633a8d5b2b2b55157b7781e2c7.png\n/kaggle/working/predicted_masks/2d9e593b6be1ac29adbe86f03d900fd1.png\n/kaggle/working/predicted_masks/3425b976973f13dd311a65d2b46d0a60.png\n/kaggle/working/predicted_masks/8eb5a9a8a8d7fcc9df8e5ad89d284483.png\n/kaggle/working/predicted_masks/cbb2a365b5574868eb60861ee1ff0b8a.png\n/kaggle/working/predicted_masks/4e2a6e51d077bad31c8c5f54ffaa27a6.png\n/kaggle/working/predicted_masks/e73749a0d21db70dd094a7f32574d6c7.png\n/kaggle/working/predicted_masks/d6240619ebebe9e9c9d00a4262b4fe4a.png\n/kaggle/working/predicted_masks/e1797c77826f9a7021bab9fc73303988.png\n/kaggle/working/predicted_masks/72d9e593b6be1ac29adbe86f03d900fd.png\n/kaggle/working/predicted_masks/f8e5ad89d2844837f2a0f1536ad3f6a5.png\n/kaggle/working/predicted_masks/998906d3694abb47953b0e4909384b57.png\n/kaggle/working/predicted_masks/a6e51d077bad31c8c5f54ffaa27a6235.png\n/kaggle/working/predicted_masks/ad43fe2cd066b9fdbc3bbc04a3afe1f1.png\n/kaggle/working/predicted_masks/aafac813fe3ccba3e032dd2948a80c64.png\n/kaggle/working/predicted_masks/c695325ded465efde988dfb96d081533.png\n/kaggle/working/predicted_masks/be4d18d5401f659532897255ce2dd4ae.png\n/kaggle/working/predicted_masks/0398846f67b5df7cdf3f33c3ca4d5060.png\n/kaggle/working/predicted_masks/71f2fd85a04faeeb2b535797395305af.png\n/kaggle/working/predicted_masks/eecd70ebce6347c491b37c8c2e5a64a8.png\n/kaggle/working/predicted_masks/e5e8f14e1e0ae936de314f2d95e6c487.png\n/kaggle/working/predicted_masks/d077bad31c8c5f54ffaa27a623511c38.png\n/kaggle/working/predicted_masks/4baddc22268d4b4ef4d95ceea1195799.png\n/kaggle/working/predicted_masks/b70dd094a7f32574d6c748c41743c6c0.png\n/kaggle/working/predicted_masks/39d6aad6bb0170a40ed32deef71fbe08.png\n/kaggle/working/predicted_masks/3dd311a65d2b46d0a6085835c525af63.png\n/kaggle/working/predicted_masks/c656702fa602bb3c7abacdbd7e6afd56.png\n/kaggle/working/predicted_masks/45b21960c94b0aab4c024a573c692195.png\n/kaggle/working/predicted_masks/677a6b1f2c6d40b3bbba8f6c704801b3.png\n/kaggle/working/predicted_masks/cc5cfd263f1f90be28799235026b3550.png\n/kaggle/working/predicted_masks/27738677a6b1f2c6d40b3bbba8f6c704.png\n/kaggle/working/predicted_masks/cdf3f33c3ca4d5060a633a8d5b2b2b55.png\n/kaggle/working/predicted_masks/780fd497e1c0e9082ea2c193ac8d551c.png\n/kaggle/working/predicted_masks/8954bb13d3727c7e5e1069646f2f0bb8.png\n/kaggle/working/predicted_masks/625559c7e610b1531871f2fd85a04fae.png\n/kaggle/working/predicted_masks/02fa602bb3c7abacdbd7e6afd56ea7bc.png\n/kaggle/working/predicted_masks/e8bfb905b78a91391adc0bb223c4eaf3.png\n/kaggle/working/predicted_masks/c41545ba55aadaa77712a48e11d579d9.png\n/kaggle/working/predicted_masks/e2cd066b9fdbc3bbc04a3afe1f119f21.png\n/kaggle/working/predicted_masks/1c0e9082ea2c193ac8d551c149b60f29.png\n/kaggle/working/predicted_masks/63b8318ecf467d7ad048df39beb17636.png\n/kaggle/working/predicted_masks/dc70626ab4ec3d46e602b296cc5cfd26.png\n/kaggle/working/predicted_masks/1db239dda50f954ba59c7de13a35276a.png\n/kaggle/working/predicted_masks/5026b3550534bca540e24f489284b8e6.png\n/kaggle/working/predicted_masks/7af2ed9fbb63b28163a745959c039830.png\n/kaggle/working/predicted_masks/e1e0ae936de314f2d95e6c487ffa651b.png\n/kaggle/working/predicted_masks/cf6644589e532a9ee954f81faedbce39.png\n/kaggle/working/predicted_masks/6f4d4987ea3b4bae5672a230194c5a08.png\n/kaggle/working/predicted_masks/7fda8019410b1fcf0625f608b4ce9762.png\n/kaggle/working/predicted_masks/f8e26031fbb5e52c41545ba55aadaa77.png\n/kaggle/working/predicted_masks/94a7f32574d6c748c41743c6c08a1d1a.png\n/kaggle/working/predicted_masks/80c643782707d7c359e27888daefee82.png\n/kaggle/working/predicted_masks/e19769fa2d37d32780fd497e1c0e9082.png\n/kaggle/working/predicted_masks/a48847ae8395e56a6d9ba9d45c3dbc69.png\n/kaggle/working/predicted_masks/26679bff55177a34fc01019eec999fd8.png\n/kaggle/working/predicted_masks/6ddca6ee1af35b65bd9ea42cfcfedb5e.png\n/kaggle/working/predicted_masks/e9082ea2c193ac8d551c149b60f29653.png\n/kaggle/working/predicted_masks/343f27ebc5d92b9076135d76d0bbd4ce.png\n/kaggle/working/predicted_masks/2ed9fbb63b28163a745959c03983064a.png\n/kaggle/working/predicted_masks/3f33c3ca4d5060a633a8d5b2b2b55157.png\n/kaggle/working/predicted_masks/2a365b5574868eb60861ee1ff0b8a4f6.png\n/kaggle/working/predicted_masks/1002ec4a1fe748f3085f1ce88cbdf366.png\n/kaggle/working/predicted_masks/3b8318ecf467d7ad048df39beb176363.png\n/kaggle/working/predicted_masks/5c1346e62522325c1b9c4fc9cbe1eca1.png\n/kaggle/working/predicted_masks/4fda8daadc8dd23ae214d84b5dec33fd.png\n/kaggle/working/predicted_masks/eb1ef57af2ed9fbb63b28163a745959c.png\n/kaggle/working/predicted_masks/fb905b78a91391adc0bb223c4eaf3372.png\n/kaggle/working/predicted_masks/8cbdf366e057db382b8564872a27301a.png\n/kaggle/working/predicted_masks/4f437f0019f7e6af7d7147763bdfb928.png\n/kaggle/working/predicted_masks/6679bff55177a34fc01019eec999fd84.png\n/kaggle/working/predicted_masks/cf464aa36bf7c09a3bb0e5ca159410b9.png\n/kaggle/working/predicted_masks/ea42b4eebc9e5a87e443434ac60af150.png\n/kaggle/working/predicted_masks/df8e26031fbb5e52c41545ba55aadaa7.png\n/kaggle/working/predicted_masks/60a633a8d5b2b2b55157b7781e2c706c.png\n/kaggle/working/predicted_masks/b21960c94b0aab4c024a573c692195f8.png\n/kaggle/working/predicted_masks/fdbc3bbc04a3afe1f119f21b248d152b.png\n/kaggle/working/predicted_masks/6b83ef461c2a337948a41964c1d4f50a.png\n/kaggle/working/predicted_masks/a51625559c7e610b1531871f2fd85a04.png\n/kaggle/working/predicted_masks/dd094a7f32574d6c748c41743c6c08a1.png\n/kaggle/working/predicted_masks/5664c1711b62f15ec83b97bb11e8e0c4.png\n/kaggle/working/predicted_masks/0fca6a4248a41e8db8b4ed633b456aaa.png\n/kaggle/working/predicted_masks/0a0317371a966bf4b3466463a3c64db1.png\n/kaggle/working/predicted_masks/88e16d4ca6160127cd1d5ff99c267599.png\n/kaggle/working/predicted_masks/d6bf62f215f0da4ad3a7ab8df9da7386.png\n/kaggle/working/predicted_masks/50534bca540e24f489284b8e6953ad88.png\n/kaggle/working/predicted_masks/f13dd311a65d2b46d0a6085835c525af.png\n/kaggle/working/predicted_masks/ff05dec1eb3a70b145a7d8d3b6c0ed75.png\n/kaggle/working/predicted_masks/7330398846f67b5df7cdf3f33c3ca4d5.png\n/kaggle/working/predicted_masks/5e8f14e1e0ae936de314f2d95e6c487f.png\n/kaggle/working/predicted_masks/7f0019f7e6af7d7147763bdfb928d788.png\n/kaggle/working/predicted_masks/87133b51209db6dcdda5cc8a788edaeb.png\n/kaggle/working/predicted_masks/8395e56a6d9ba9d45c3dbc695325ded4.png\n/kaggle/working/predicted_masks/0a5f3601ad4f13ccf1f4b331a412fc44.png\n/kaggle/working/predicted_masks/314fe384eb2ba3adfda6c1899fdc9837.png\n/kaggle/working/predicted_masks/f62f215f0da4ad3a7ab8df9da7386835.png\n/kaggle/working/predicted_masks/0626ab4ec3d46e602b296cc5cfd263f1.png\n/kaggle/working/predicted_masks/4e8bfb905b78a91391adc0bb223c4eaf.png\n/kaggle/working/predicted_masks/fcd6da15fc656702fa602bb3c7abacdb.png\n/kaggle/working/predicted_masks/af35b65bd9ea42cfcfedb5eb2a0e4b50.png\n/kaggle/working/predicted_masks/13dd311a65d2b46d0a6085835c525af6.png\n/kaggle/working/predicted_masks/7936140a2d5fc1443c4e445927738677.png\n/kaggle/working/predicted_masks/461c2a337948a41964c1d4f50a5f3601.png\n/kaggle/working/predicted_masks/afe1f119f21b248d152b672ab3492fc6.png\n/kaggle/working/predicted_masks/4ca6160127cd1d5ff99c267599fc487b.png\n/kaggle/working/predicted_masks/3c3ca4d5060a633a8d5b2b2b55157b77.png\n/kaggle/working/predicted_masks/30c2f4fc276ed9f178dc2f4af6266509.png\n/kaggle/working/predicted_masks/8b8ec74baddc22268d4b4ef4d95ceea1.png\n/kaggle/working/predicted_masks/633a8d5b2b2b55157b7781e2c706c75c.png\n/kaggle/working/predicted_masks/6231002ec4a1fe748f3085f1ce88cbdf.png\n/kaggle/working/predicted_masks/5b21960c94b0aab4c024a573c692195f.png\n/kaggle/working/predicted_masks/285e26c90e1797c77826f9a7021bab9f.png\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}